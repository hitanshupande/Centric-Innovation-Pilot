{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centric Innovation Pilot: Employee Recommendation Engine\n",
    "------------\n",
    "\n",
    "#### Hypothesis\n",
    " \n",
    "In a professional services organization, we can improve overall utilization and reduce dependency on recruiting by using aggregated workforce data to produce machine generated staffing suggestions.\n",
    "\n",
    "![](Innovation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For v0.1 we had access to resume data for Centric employees which was pulled from Centricity. This is what it looked like:\n",
    "\n",
    "\n",
    "![](ResumeSample.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one file has the resume information for 331 employees\n",
    "\n",
    "#### Step 1: We will import the file and check it's encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'windows-1252', 'confidence': 0.73}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import chardet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "fileName = 'D:/Python/Centric/output/EverySingleResume.txt'\n",
    "\n",
    "with open(fileName, 'rb') as f:\n",
    "    result = chardet.detect(f.readline())\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 2: Read contents of the file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77789</th>\n",
       "      <td>Oswaldo Gonzalez 2015.TXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77790</th>\n",
       "      <td>Oswaldo Gonzalez 2015.TXT</td>\n",
       "      <td>Foreign Language Skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77791</th>\n",
       "      <td>Oswaldo Gonzalez 2015.TXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77792</th>\n",
       "      <td>Oswaldo Gonzalez 2015.TXT</td>\n",
       "      <td>English – Fluent in Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77793</th>\n",
       "      <td>Oswaldo Gonzalez 2015.TXT</td>\n",
       "      <td>Spanish – Native</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                             1\n",
       "77789  Oswaldo Gonzalez 2015.TXT                           NaN\n",
       "77790  Oswaldo Gonzalez 2015.TXT       Foreign Language Skills\n",
       "77791  Oswaldo Gonzalez 2015.TXT                           NaN\n",
       "77792  Oswaldo Gonzalez 2015.TXT  English – Fluent in Business\n",
       "77793  Oswaldo Gonzalez 2015.TXT             Spanish – Native "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(fileName,sep=\"^\", skiprows=2, header=None, encoding='windows-1252',error_bad_lines=False)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Clean up the name field and remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    df = df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    df[0] = df[0].replace({'Centric': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'centric': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'CENTRIC': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Resume': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'resume': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'New': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Current': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Profile': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Consulting': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'.txt': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'.TXT': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'-': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'_': ''}, regex=True)\n",
    "    df[0] = df[0].replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "    df[0] = df[0].replace(r\"[*0-9]\",\"\", regex=True)\n",
    "    df[0] = df[0].replace({'\\.': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'January': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'February': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Feburary': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'March': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'April': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'May': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'June': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'July': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'August': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'September': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'October': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'November': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'December': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Feb': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Apr': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'May': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Jun': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Aug': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Sep': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Oct': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Nov': ''}, regex=True)\n",
    "    df[0] = df[0].replace({'Dec': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Remove any trailing white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aaron Aude', 'Abrams', 'Adam Burkholder', 'Adam Wiggershaus',\n",
       "       'AJ Flynn'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df[0] = df[0].str.strip()\n",
    "    uniqueNames = df[0].unique()\n",
    "    uniqueNames[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Group all the resume lines into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResourceName</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Nixon</td>\n",
       "      <td>ÿþ   Andrew Nixon   Associate Profile   Andrew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AJ Flynn</td>\n",
       "      <td>ÿþ   Anthony J. Flynn   Professional Experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Aude</td>\n",
       "      <td>Aaron Aude   Associate Profile   Aaron has ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abrams</td>\n",
       "      <td>ÿþANGELA ABRAMS   105 Brookhill Drive   Gahann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Burkholder</td>\n",
       "      <td>ÿþ   Adam Burkholder   Associate Profile   Ada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ResourceName                                               text\n",
       "0          A Nixon  ÿþ   Andrew Nixon   Associate Profile   Andrew...\n",
       "1         AJ Flynn  ÿþ   Anthony J. Flynn   Professional Experienc...\n",
       "2       Aaron Aude  Aaron Aude   Associate Profile   Aaron has ove...\n",
       "3           Abrams  ÿþANGELA ABRAMS   105 Brookhill Drive   Gahann...\n",
       "4  Adam Burkholder  ÿþ   Adam Burkholder   Associate Profile   Ada..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1] = df[1].astype(str) + \" \"\n",
    "df_new = df.groupby([0]).sum().reset_index() \n",
    "df_new.rename(columns={0:'ResourceName'}, inplace=True)\n",
    "df_new.rename(columns={1:'text'}, inplace=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Convert resume text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ÿþ   andrew nixon   associate profile   andrew...\n",
       "1    ÿþ   anthony j. flynn   professional experienc...\n",
       "2    aaron aude   associate profile   aaron has ove...\n",
       "3    ÿþangela abrams   105 brookhill drive   gahann...\n",
       "4    ÿþ   adam burkholder   associate profile   ada...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.text = df_new['text'].str.lower()\n",
    "df_new.text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: In order to build a recommendation engine, we will build a sparse matrix from the resume text. We will do so by converting the collection of resumes to a matrix of TF-IDF features. Using this matrix, we will calculate cosine distance between resumes and rank them in their sorted order. The top 5 documents will be our top 5 recommendations based on an input of the Employee Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156     Hendarsin Lukito\n",
      "181          Jeff Benson\n",
      "170         Jana Sanders\n",
      "152    Hanmanth Jogiraju\n",
      "Name: ResourceName, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel        \n",
    "tfidf = TfidfVectorizer().fit_transform(df_new.text) \n",
    "   \n",
    "def similar_resume(name_of_employee):\n",
    "    #Find location of name in dataframe\n",
    "    x = df_new[df_new['ResourceName'].str.contains('^'+name_of_employee)].index\n",
    "    y = calculate_cosine_similarity(x[0])\n",
    "    print(df_new.ResourceName[y])                \n",
    "         \n",
    "                \n",
    "def calculate_cosine_similarity(employee_loc):\n",
    "    cosine_similarities = linear_kernel(tfidf[employee_loc-1:employee_loc], tfidf).flatten()  \n",
    "    related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "    return related_docs_indices\n",
    "    \n",
    "try:\n",
    "    similar_resume('Hitanshu Pande')\n",
    "except:\n",
    "    print(\"Resume not in database!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------------\n",
    "#### As seen above, the employees similar to 'Hitanshu Pande' were Hendersin Lukito, Jeff Benson, Jana Sanders and Hanmanth Jogiraju. \n",
    "\n",
    "#### This is a first step towards determining the right employee that should be suggested for a particular job opening. Based on enriched past data, we can make mature recommendations based on previous staffing decisions, availablility, travel preferences, SO and IV allegiances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
